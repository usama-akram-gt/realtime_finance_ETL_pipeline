# ğŸš€ Real-Time Finance ETL Pipeline

A production-ready real-time financial data pipeline built with modern data engineering technologies for enterprise-scale processing and analytics.

## ğŸ“Š Pipeline Walkthrough

### **Data Flow Architecture**
```
ğŸ“ˆ Financial APIs â†’ ğŸ”„ Apache Kafka â†’ âš¡ Apache Spark â†’ ğŸ—„ï¸ PostgreSQL â†’ ğŸ“‹ DBT â†’ ğŸ“Š Analytics
```

### **Step-by-Step Process**

1. **ğŸ“¥ Data Ingestion**
   - **Yahoo Finance API** fetches real-time market data
   - **Python async services** handle rate limiting and error recovery
   - **Structured logging** tracks all ingestion activities

2. **ğŸ”„ Message Streaming** 
   - **Apache Kafka** queues financial data for reliable processing
   - **Zookeeper** manages Kafka cluster coordination
   - **Real-time data flow** ensures low-latency processing

3. **âš¡ Data Processing**
   - **Apache Spark** processes streaming data in real-time
   - **Technical indicators** (RSI, MACD, Moving Averages)
   - **Anomaly detection** and volatility calculations

4. **ğŸ—„ï¸ Data Storage**
   - **PostgreSQL** stores processed financial data
   - **Optimized schemas** for time-series analysis
   - **Redis caching** for high-frequency queries

5. **ğŸ”§ Orchestration**
   - **Apache Airflow** manages pipeline workflows
   - **Automated scheduling** every 15 minutes
   - **Error handling** and retry mechanisms

6. **ğŸ“‹ Data Transformation**
   - **DBT models** transform raw data into analytics tables
   - **Staging â†’ Marts** data modeling approach
   - **Data quality tests** ensure reliability

7. **ğŸ“Š Analytics & Monitoring**
   - **Real-time dashboards** for market insights
   - **Prometheus metrics** for system monitoring
   - **Structured alerts** for anomalies

## ğŸ› ï¸ Technology Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Orchestration** | Apache Airflow | Workflow management & scheduling |
| **Streaming** | Apache Kafka + Zookeeper | Message queuing & real-time data flow |
| **Processing** | Apache Spark | Distributed data processing |
| **Storage** | PostgreSQL + Redis | Data persistence & caching |
| **Transformation** | DBT | Data modeling & transformations |
| **Quality** | Great Expectations | Data validation & testing |
| **APIs** | Yahoo Finance | Financial market data source |
| **Infrastructure** | Docker + Docker Compose | Containerized deployment |

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Python 3.13+
- 8GB+ RAM recommended

### Setup & Run
```bash
# 1. Clone repository
git clone https://github.com/usama-akram-gt/realtime_finance_ETL_pipeline.git
cd realtime_finance_ETL_pipeline

# 2. Create virtual environment
python3 -m venv venv
source venv/bin/activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Start infrastructure
docker-compose up -d

# 5. Test pipeline
python3 test_pipeline.py
```

## ğŸ“ˆ Access Services

- **Airflow UI**: http://localhost:8081 (admin/admin123)
- **Spark Master**: http://localhost:8080  
- **PostgreSQL**: localhost:5432 (postgres/postgres)
- **Kafka**: localhost:9092

## ğŸ—ï¸ Project Structure

```
src/
â”œâ”€â”€ ingestion/          # Data ingestion services
â”œâ”€â”€ streaming/          # Kafka streaming components  
â”œâ”€â”€ spark_jobs/         # Spark processing jobs
â”œâ”€â”€ storage/            # Database operations
â”œâ”€â”€ dbt/                # DBT transformations
â”œâ”€â”€ airflow/            # Workflow orchestration
â””â”€â”€ great_expectations/ # Data quality checks
```

## ğŸ“Š Key Features

- **âš¡ Real-time Processing**: Sub-second data ingestion and processing
- **ğŸ”„ Fault Tolerance**: Automatic retry and error recovery mechanisms  
- **ğŸ“ˆ Scalability**: Horizontally scalable architecture
- **ğŸ›¡ï¸ Data Quality**: Comprehensive validation and testing
- **ğŸ“Š Monitoring**: Full observability with metrics and logging
- **ğŸ­ Production Ready**: Enterprise-grade coding practices

## ğŸ’¡ Use Cases

- **Trading Analytics**: Real-time market analysis and decision support
- **Risk Management**: Portfolio risk assessment and monitoring
- **Market Research**: Historical and real-time market trend analysis
- **Algorithmic Trading**: Data feed for trading algorithms

Built with â¤ï¸ for modern data engineering